{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPMzu6aN31wPpPodHsLaQRq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Operationalizing Machine Learning Models"],"metadata":{"id":"2lZJu3dY9BoN"}},{"cell_type":"markdown","source":["## Consuming a Python Model from a Python Client"],"metadata":{"id":"T4E0dYRY9MCH"}},{"cell_type":"code","source":["#To demonstrate I'm building and training the titanic model from earlier but instead of making predictions I'll save the model to a pickle file"],"metadata":{"id":"zh37M11FuZRa","executionInfo":{"status":"ok","timestamp":1680716972675,"user_tz":240,"elapsed":341,"user":{"displayName":"Zack Gamble","userId":"07180195119600936382"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PStRBr1F89jo","executionInfo":{"status":"ok","timestamp":1680716976713,"user_tz":240,"elapsed":4041,"user":{"displayName":"Zack Gamble","userId":"07180195119600936382"}}},"outputs":[],"source":["import pickle\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","\n","df = pd.read_csv(\"https://raw.githubusercontent.com/jeffprosise/Applied-Machine-Learning/main/Chapter%203/Data/titanic.csv\")\n","df = df[[\"Survived\",\"Age\",\"Sex\",\"Pclass\"]]\n","df = pd.get_dummies(df,columns=[\"Sex\",\"Pclass\"])\n","df.dropna(inplace=True)\n","\n","x = df.drop(\"Survived\",axis=1)\n","y = df[\"Survived\"]\n","\n","model = LogisticRegression(random_state=0)\n","model.fit(x,y)\n","\n","pickle.dump(model,open(\"titanic.pkl\",\"wb\"))"]},{"cell_type":"code","source":["#To invoke the model a python client uses pickle load to load the model and make a prediction\n","\n","model = pickle.load(open(\"titanic.pkl\",\"rb\"))\n","\n","female = pd.DataFrame({ 'Age': [30], 'Sex_female': [1], 'Sex_male': [0],\n","                        'Pclass_1': [1], 'Pclass_2': [0], 'Pclass_3': [0] })\n","\n","probability = model.predict_proba(female)[0][1]\n","print(f'Probability of survival: {probability:.1%}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ol9caHK8ve9t","executionInfo":{"status":"ok","timestamp":1680716976713,"user_tz":240,"elapsed":7,"user":{"displayName":"Zack Gamble","userId":"07180195119600936382"}},"outputId":"ba4ab43b-2df6-43b3-8877-ee7267ff5fbb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Probability of survival: 92.8%\n"]}]},{"cell_type":"code","source":["#The following code trains and saves a sentiment-analysis model. This time, a pipeline containing a \n","#CountVectorizer and a LogisticRegression classifier is saved:\n","\n","\n","import pickle\n","import pandas as pd\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import make_pipeline\n"," \n","df = pd.read_csv(\"https://raw.githubusercontent.com/jeffprosise/Applied-Machine-Learning/main/Chapter%204/Data/reviews.csv\", encoding=\"ISO-8859-1\")\n","df = df.drop_duplicates()\n"," \n","x = df['Text']\n","y = df['Sentiment']\n"," \n","vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english',\n","                             min_df=20)\n","\n","model = LogisticRegression(max_iter=1000, random_state=0)\n","pipe = make_pipeline(vectorizer, model)\n","pipe.fit(x, y)\n"," \n","pickle.dump(pipe, open('sentiment.pkl', 'wb'))"],"metadata":{"id":"9SNcqRSwwEwv","executionInfo":{"status":"ok","timestamp":1680717016240,"user_tz":240,"elapsed":39530,"user":{"displayName":"Zack Gamble","userId":"07180195119600936382"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#deserialize the pipeline and call predict_proba to score a line of text for sentiment with a few simple lines of code:\n","\n","import pickle\n","\n","pipe = pickle.load(open('sentiment.pkl', 'rb'))\n","pipe.predict_proba(['Great food and excellent service!'])[0][1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdNf9A3gwg22","executionInfo":{"status":"ok","timestamp":1680717016859,"user_tz":240,"elapsed":637,"user":{"displayName":"Zack Gamble","userId":"07180195119600936382"}},"outputId":"9b59384f-66b1-43a9-9371-9fa7b23d60b9"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8826850598493062"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Using ONNX to Bridge the Language Gap"],"metadata":{"id":"fillWYDvi8zB"}},{"cell_type":"code","source":["!pip install Skl2onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L_7gJtYmxDYi","executionInfo":{"status":"ok","timestamp":1680717157605,"user_tz":240,"elapsed":8839,"user":{"displayName":"Zack Gamble","userId":"07180195119600936382"}},"outputId":"a0ecd11f-1504-4a07-f597-acfc721369e8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting Skl2onnx\n","  Downloading skl2onnx-1.14.0-py2.py3-none-any.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.0/294.0 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnx>=1.2.1\n","  Downloading onnx-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn<1.3,>=0.19 in /usr/local/lib/python3.9/dist-packages (from Skl2onnx) (1.2.2)\n","Collecting onnxconverter-common>=1.7.0\n","  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.9/dist-packages (from onnx>=1.2.1->Skl2onnx) (3.20.3)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx>=1.2.1->Skl2onnx) (1.22.4)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx>=1.2.1->Skl2onnx) (4.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxconverter-common>=1.7.0->Skl2onnx) (23.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<1.3,>=0.19->Skl2onnx) (1.1.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<1.3,>=0.19->Skl2onnx) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<1.3,>=0.19->Skl2onnx) (3.1.0)\n","Installing collected packages: onnx, onnxconverter-common, Skl2onnx\n","Successfully installed Skl2onnx-1.14.0 onnx-1.13.1 onnxconverter-common-1.13.0\n"]}]},{"cell_type":"code","source":["#using the built in method convert_sklearn to save a trained Scikit model to .onnx file that can be used in other programming languages\n","\n","from skl2onnx import convert_sklearn\n","from skl2onnx.common.data_types import StringTensorType\n","\n","initial_type = [(\"string_input\",StringTensorType([None,1]))]\n","\n","onnx = convert_sklearn(pipe,initial_types=initial_type)\n","\n","with open(\"sentiment.onnx\",\"wb\") as f:\n","  f.write(onnx.SerializeToString())"],"metadata":{"id":"MdtsGMjVjHFT","executionInfo":{"status":"ok","timestamp":1680717434279,"user_tz":240,"elapsed":10134,"user":{"displayName":"Zack Gamble","userId":"07180195119600936382"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ytkyblptkKOF"},"execution_count":null,"outputs":[]}]}